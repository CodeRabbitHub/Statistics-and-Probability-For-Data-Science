{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing\n",
    "\n",
    "Before delving into the intricacies of hypothesis testing, it's imperative to grasp some foundational concepts.\n",
    "\n",
    "## Population Parameters vs. Sample Statistics\n",
    "\n",
    "A **Parameter** denotes a characteristic of an entire population, such as the population mean. As it's typically impractical to measure the entire population, the true value of the parameter often eludes us. Commonly used parameters in statistics, like the population mean and standard deviation, are symbolized by Greek letters such as $\\mu$ (mu) and $\\sigma$ (sigma).\n",
    "\n",
    "Conversely, a **Statistic** represents a characteristic calculated from a sample. For instance, computing the mean and standard deviation of a sample yields sample statistics. In statistical parlance, sample parameters are denoted by Latin letters.\n",
    "\n",
    "**Inferential statistics** entails leveraging sample statistics to draw inferences about a population. This involves using sample statistics to estimate population parameters. To ensure validity, representative sampling techniques like random sampling are pivotal for obtaining unbiased estimates. Unbiased estimates are considered accurate on average, whereas biased estimates systematically deviate from the truth.\n",
    "\n",
    "## Parametric vs Nonparametric Analysis\n",
    "\n",
    "**Parametric statistics** assumes that the sample data stems from populations describable by probability distributions with fixed parameters. Consequently, parametric analysis reigns as the predominant statistical method.\n",
    "\n",
    "In contrast, **nonparametric tests** refrain from assuming any specific probability distribution for the underlying data.\n",
    "\n",
    "## Significance Level (Alpha)\n",
    "\n",
    "The **significance level** serves as a yardstick dictating the requisite strength of evidence from sample data to infer the presence of an effect in the population. Also known as alpha ($\\alpha$), it's a predetermined threshold established prior to the study. The significance level delineates the evidence threshold needed to reject the null hypothesis in favor of the alternative hypothesis.\n",
    "\n",
    "Reflecting the probability of erroneously rejecting the null hypothesis when true, the significance level quantifies the risk of asserting an effect's existence when none prevails. Lower significance levels signify heightened evidentiary thresholds, demanding more robust evidence before null hypothesis rejection. For instance, a significance level of 0.05 implies a 5% chance of committing a false positive errorâ€”declaring an effect's existence in its absence.\n",
    "\n",
    "## P-Values\n",
    "\n",
    "**P-values** gauge the strength of evidence against the null hypothesis furnished by sample data. A P-value below the established significance level denotes statistical significance.\n",
    "\n",
    "The P-value represents the probability of observing an effect in the sample data as extreme, or even more so, than the one observed if the null hypothesis held true. Essentially, it quantifies the extent to which the sample data contravenes the null hypothesis. Lower P-values denote more compelling evidence against the null hypothesis.\n",
    "\n",
    "When a P-value falls at or below the significance level, the null hypothesis is discarded, and the results are deemed statistically significant. This implies that the sample data furnishes adequate evidence to endorse the alternative hypothesis positing the effect's presence in the population.\n",
    "\n",
    "Conversely, when a P-value exceeds the significance level, the sample data fails to supply sufficient evidence for effect existence, prompting null hypothesis retention.\n",
    "\n",
    "Statistically, these verdicts translate as follows:\n",
    "\n",
    "+ Reject the null hypothesis when the P-value equals or falls below the significance level.\n",
    "+ Retain the null hypothesis when the P-value exceeds the significance level.\n",
    "\n",
    "\n",
    "## Hypothesis Testing\n",
    "\n",
    "**Hypothesis testing** is a statistical technique that evaluates the evidence of two opposing statements (hypotheses) about a population based on sample data. These hypotheses are known as the null hypothesis and the alternative hypothesis.\n",
    "\n",
    "The objective of hypothesis testing is to assess the sample statistic and its corresponding sampling error to determine which of the two hypotheses is more strongly supported by the data. If the null hypothesis can be rejected, it means that the results are statistically significant and the alternative hypothesis is favored, suggesting that an effect exists in the population.\n",
    "\n",
    "It is important to note that failing to reject the null hypothesis does not necessarily mean that the null hypothesis is true, nor does rejecting the null hypothesis necessarily imply that the alternative hypothesis is true. The results of a hypothesis test are only a suggestion or indication about the population, not a conclusive proof of either hypothesis.\n",
    "\n",
    "The null hypothesis is the theory that there is no effect (i.e., the effect size is equal to zero). It is commonly represented by $H_0$.\n",
    "\n",
    "The alternative hypothesis is the opposite theory, stating that the population parameter does not equal the value specified in the null hypothesis (i.e., there is a non-zero effect). It is usually represented by $H_1$ or $H_A$.\n",
    "\n",
    "The steps involved in hypothesis testing are as follows:\n",
    "\n",
    "1. State the null and alternative hypothesis.\n",
    "2. Specify the significance level and calculate the critical value of the test statistic.\n",
    "3. Choose the appropriate test based on factors such as the number of samples, population distribution, statistic being tested, sample size, and knowledge of the population standard deviation.\n",
    "4. Calculate the relevant test statistic (z-statistic, t-statistic, chi-square statistic, or f-statistic) or p-value.\n",
    "5. Compare the calculated test statistic with the critical test statistic or the p-value with the significance level.\n",
    "    - If using the test statistic:\n",
    "        - Reject the null hypothesis if the calculated test statistic is greater than the critical test statistic (upper-tail test)\n",
    "        - Reject the null hypothesis if the calculated test statistic is less than the critical test statistic (lower-tail test)\n",
    "    - If using the p-value:\n",
    "        - Reject the null hypothesis if the p-value is less than the significance level.\n",
    "6. Draw a conclusion based on the comparison made in step 5.\n",
    "\n",
    "## Confidence Interval\n",
    "\n",
    "A **confidence interval** can be calculated for various parameters such as population mean, population proportion, difference of population means, and difference of population proportions, among others. To construct a confidence interval, one needs to have a sample statistic that estimates the population parameter of interest and a measure of variability or standard error for that statistic. The confidence interval is calculated by adding and subtracting the standard error to the sample statistic. The result is a range of values that contains the true population parameter with a specified level of confidence.\n",
    "\n",
    "The key concept behind a confidence interval is that if we repeated our sampling process many times, the true population parameter would fall within the confidence interval for the specified percentage of these samples. For example, if we have a 95% confidence interval for a population mean, we can say that if we repeated our sampling process 100 times, the true population mean would fall within the calculated confidence interval 95 times out of 100.\n",
    "\n",
    "In conclusion, confidence intervals provide a range of plausible values for a population parameter based on the observed sample data and the level of confidence specified by the researcher. The confidence interval reflects the precision of the estimate, with wider intervals indicating less precision and narrower intervals indicating more precision.\n",
    "\n",
    "## Sampling Error\n",
    "\n",
    "A **sampling error** refers to the discrepancy between a population parameter and a sample statistic. In a study, the sampling error represents the difference between the mean calculated from a sample and the actual mean of the population. Despite using a random sample selection process, sampling errors are still a possibility as the sample may not perfectly reflect the population with regards to numerical values such as means and standard deviations. To improve the accuracy of generalizing findings from a sample to a population, it's essential to minimize the sampling error. One way to do this is to increase the sample size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
